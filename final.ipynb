{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aadae590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#setting the directory to current directory, put the ipynb in the folder with the html files\n",
    "folder_path = os.getcwd()\n",
    "\n",
    "#hold the content of each HTML file\n",
    "html_contents = []\n",
    "#hold the names of the html file\n",
    "html_ls = []\n",
    "#result df to hold the final output\n",
    "result = pd.DataFrame(columns=['filename', 'EPS'])\n",
    "\n",
    "#loop each file in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.html'):  # find html files\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "            html_contents.append(html_content)  \n",
    "            html_ls.append(filename)\n",
    "            #print(f\"Read file: {filename}\")  #quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ee2cbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[\n",
    "'Net earnings per share - basic', \n",
    "'basic',\n",
    "'GAAP net income and earnings per share',\n",
    "'Earnings per share  to common shareholders',\n",
    "'Earnings (loss) per common share',\n",
    "'Net earnings Per Common Share',\n",
    "'Adjusted earnings per share',\n",
    "'Net income per common share',\n",
    "'Earnings per share common shareholders:',\n",
    "'LOSS PER SHARE - BASIC'\n",
    "]\n",
    "\n",
    "# Function to normalize text\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  #convert all str to lower case\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  #remove punctuation\n",
    "    tokens = word_tokenize(text)  #tokenize\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]  #stemming\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "48faaab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net earnings per share – basic\n",
      "Earnings (loss) per common share\n",
      "Per Common Share\n",
      "Adjusted earnings per diluted share\n",
      "LOSS PER SHARE - BASIC AND DILUTED\n",
      "Basic earnings per share\n",
      "Basic earnings per common share\n",
      "Diluted earnings per common share:\n",
      "Net income per common share:\n",
      "BASIC EARNINGS PER SHARE:\n",
      "Basic and diluted loss per share\n",
      "Net income per common share:\n",
      "Net income per share attributable to UCT common stockholders:\n",
      "Net income (loss) per common share:\n",
      "Net loss per common share:\n",
      "Loss Per Common Share:\n",
      "Shares used to compute basic net income per share\n",
      "Earnings per share attributable\n",
      "    to Tetra Tech:\n",
      "Income (loss) per share—basic\n",
      "NET EARNINGS PER COMMON SHARE:\n",
      "Basic Earnings per Share\n",
      "Net (loss) income per share attributable to the Company\n",
      "Earnings per common share:\n",
      "Basic net income per share\n",
      "Earnings per share:\n",
      "Net loss per share:\n",
      "Net income per common share\n",
      "Basic and diluted earnings per share\n",
      "Earnings per share:\n",
      "Net income per common share\n",
      "Basic and diluted net (loss) income per common share\n",
      "Per Common Share Data:\n",
      "Basic and diluted net loss per share\n",
      "Net income (loss) per share - basic\n",
      "Net income (loss) per common share - basic\n",
      "Earnings per share - basic\n",
      "Net income per common share: (1)\n",
      "(Loss) earnings per share\n",
      "(Loss) Earnings Per Share:\n",
      "Basic earnings per share\n",
      "Earnings per share:\n",
      "Basic earnings (loss) per share\n",
      "Basic earnings per share:\n",
      "Net (loss) income per diluted common share\n",
      "Adjusted net income per share\n",
      "(LOSS) EARNINGS PER SHARE\n",
      "Basic and diluted loss per share:\n",
      "Adjusted basic net income per share:\n",
      "Earnings per ordinary share\n",
      "Earnings (loss) per share:\n"
     ]
    }
   ],
   "source": [
    "# In the soup, use machine learning to find the target cell that holds EPS label\n",
    "def find_most_similar_cell(soup):\n",
    "\n",
    "    #extract all cells from soup\n",
    "    cells = soup.find_all('td')\n",
    "    if not cells:\n",
    "        return \"No cells found.\"\n",
    "\n",
    "    #extract and normalizes cells texts\n",
    "    cell_texts = [cell.get_text(\" \", strip=True) for cell in cells]\n",
    "    normalized_cell_texts = [normalize_text(text) for text in cell_texts]\n",
    "\n",
    "    #normalize dictionary texts\n",
    "    normalized_texts = [normalize_text(text) for text in texts]\n",
    "\n",
    "    #vectorize all texts\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_texts = normalized_texts + normalized_cell_texts\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "     #calculate cosine similarity between each input text and each cell\n",
    "    highest_similarity = -1\n",
    "    most_similar_cell_text = \"\"\n",
    "    for i, text in enumerate(normalized_texts):\n",
    "        similarity_scores = cosine_similarity(tfidf_matrix[i:i+1], tfidf_matrix[len(normalized_texts):])\n",
    "        for idx in similarity_scores.argsort()[0][::-1]:  #iterate over indices from highest to lowest similarity\n",
    "            candidate_text = cell_texts[idx]\n",
    "            if len(candidate_text.split()) >= 3:  #check if the candidate text has more than three words, ex'Basic'\n",
    "                max_similarity = similarity_scores[0, idx]\n",
    "                if max_similarity > highest_similarity:\n",
    "                    highest_similarity = max_similarity\n",
    "                    most_similar_cell_text = candidate_text\n",
    "                break  #stop after finding the first match with more than three words\n",
    "\n",
    "    return most_similar_cell_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#finetune our text dictionary for accuracy\n",
    "for i in range(50):\n",
    " soup = BeautifulSoup(html_contents[i], 'html.parser')\n",
    " print(find_most_similar_cell(soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c1590ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to parse EPS value from cell with string information, it inputs str and output float\n",
    "def parse_number(price):\n",
    "    try:\n",
    "        # Strip the dollar sign, any spaces, and commas, and right brakcet\n",
    "        price = price.strip().replace(\"$\", \"\").replace(\",\", \"\").replace(\")\", \"\")\n",
    "        \n",
    "        # Return 0 if the stripped price is an empty string\n",
    "        if price == \"\":\n",
    "            return 0\n",
    "        \n",
    "        # Check if the number is enclosed in a left parenthesis\n",
    "        if price.startswith(\"(\"):\n",
    "            # Remove the left parenthesis\n",
    "            price = price[1:]\n",
    "            # Convert to negative float, even if there's no closing parenthesis\n",
    "            return -float(price)\n",
    "        else:\n",
    "            # Convert to positive float\n",
    "            return float(price)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting '{price}' to float: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fcfe408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 1 0000004977-20-000054.html\n",
      "Net earnings per share – basic 0.78\n",
      "file 2 0000008947-20-000044.html\n",
      "Earnings (loss) per common share -0.41\n",
      "file 3 0000046080-20-000050.html\n",
      "Per Common Share 0\n",
      "file 4 0000066570-20-000013.html\n",
      "Adjusted earnings per diluted share 1.18\n",
      "file 5 0000314808-20-000062.html\n",
      "LOSS PER SHARE - BASIC AND DILUTED -15.19\n",
      "file 6 0000706129-20-000012.html\n",
      "Basic earnings per share 0.26\n",
      "file 7 0000846617-20-000024.html\n",
      "Basic earnings per common share 0.47\n",
      "file 8 0000874766-20-000033.html\n",
      "Diluted earnings per common share: 0.74\n",
      "file 9 0000875320-20-000014.html\n",
      "Net income per common share: 2.32\n",
      "file 10 0000892537-20-000010.html\n",
      "BASIC EARNINGS PER SHARE: 0.71\n",
      "file 11 0000895419-20-000042.html\n",
      "Basic and diluted loss per share -0.57\n",
      "file 12 0000939057-20-000186.html\n",
      "Net income per common share: 0.61\n",
      "file 13 0000950103-20-008424.html\n",
      "Net income per share attributable to UCT common stockholders: 0.24\n",
      "file 14 0001008654-20-000048.html\n",
      "Net income (loss) per common share: -0.16\n",
      "file 15 0001104659-20-052683.html\n",
      "Net loss per common share: -0.42\n",
      "file 16 0001104659-20-052792.html\n",
      "Loss Per Common Share: 0\n",
      "file 17 0001104659-20-053353.html\n",
      "Shares used to compute basic net income per share 101235.0\n",
      "file 18 0001104659-20-053534.html\n",
      "Earnings per share attributable\n",
      "    to Tetra Tech: 0.67\n",
      "file 19 0001104659-20-053563.html\n",
      "Income (loss) per share—basic 3.17\n",
      "file 20 0001140361-20-010070.html\n",
      "NET EARNINGS PER COMMON SHARE: 0\n",
      "file 21 0001141391-20-000089.html\n",
      "Basic Earnings per Share 1.68\n",
      "file 22 0001157523-20-000597.html\n",
      "Net (loss) income per share attributable to the Company -0.03\n",
      "file 23 0001157523-20-000599.html\n",
      "Earnings per common share: 0.57\n",
      "file 24 0001157523-20-000600.html\n",
      "Basic net income per share 0.11\n",
      "file 25 0001165002-20-000083.html\n",
      "Earnings per share: 0.13\n",
      "file 26 0001171843-20-003035.html\n",
      "Net loss per share: -6.79\n",
      "file 27 0001193125-20-124288.html\n",
      "Net income per common share 2.01\n",
      "file 28 0001193125-20-124568.html\n",
      "Basic and diluted earnings per share 0.3\n",
      "file 29 0001193125-20-126089.html\n",
      "Earnings per share: 1.41\n",
      "file 30 0001193125-20-126683.html\n",
      "Net income per common share 1.52\n",
      "file 31 0001289945-20-000036.html\n",
      "Basic and diluted net (loss) income per common share -0.24\n",
      "file 32 0001299709-20-000078.html\n",
      "Per Common Share Data: 0\n",
      "file 33 0001323885-20-000027.html\n",
      "Basic and diluted net loss per share -0.42\n",
      "file 34 0001373715-20-000098.html\n",
      "Net income (loss) per share - basic 0.25\n",
      "file 35 0001423689-20-000040.html\n",
      "Net income (loss) per common share - basic -4.46\n",
      "file 36 0001436425-20-000011.html\n",
      "Earnings per share - basic 0.21\n",
      "file 37 0001538263-20-000014.html\n",
      "Net income per common share: (1) 0\n",
      "file 38 0001564590-20-019396.html\n",
      "(Loss) earnings per share -3.15\n",
      "file 39 0001564590-20-019421.html\n",
      "(Loss) Earnings Per Share: -0.24\n",
      "file 40 0001564590-20-019431.html\n",
      "Basic earnings per share 1.08\n",
      "file 41 0001564590-20-019442.html\n",
      "Earnings per share: 1.0\n",
      "file 42 0001564590-20-019726.html\n",
      "Basic earnings (loss) per share 0.08\n",
      "file 43 0001564590-20-019755.html\n",
      "Basic earnings per share: 2.0\n",
      "file 44 0001564590-20-019760.html\n",
      "Net (loss) income per diluted common share -2.21\n",
      "file 45 0001576427-20-000032.html\n",
      "Adjusted net income per share 0.62\n",
      "file 46 0001620459-20-000067.html\n",
      "(LOSS) EARNINGS PER SHARE -1.21\n",
      "file 47 0001678463-20-000062.html\n",
      "Basic and diluted loss per share: -0.22\n",
      "file 48 0001691303-20-000019.html\n",
      "Adjusted basic net income per share: 0.39\n",
      "file 49 0001720635-20-000018.html\n",
      "Earnings per ordinary share 0.11\n",
      "file 50 0001722482-20-000089.html\n",
      "Earnings (loss) per share: 0.05\n"
     ]
    }
   ],
   "source": [
    "#write a function to find the EPS for the label in the soup tables, it will return a EPS value\n",
    "def find_value_after_label(soup, label):\n",
    "\n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    # Iterate over each table\n",
    "    for table in tables:\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        # Iterate over each row within the table\n",
    "        for i, row in enumerate(rows):\n",
    "            cells = row.find_all(['td'])\n",
    "            \n",
    "            # Check if the label exists in this row\n",
    "            for j, cell in enumerate(cells):\n",
    "                if label in cell.get_text(strip=True):\n",
    "                    # Label found, check the same row for valid value\n",
    "                    for value_cell in cells[j+1:]:\n",
    "                        value_text = value_cell.get_text(strip = True)\n",
    "                        if re.search(r'[0-9]', value_text): # Make sure there are numbers in the cell\n",
    "                            return parse_number(value_text)\n",
    "                        \n",
    "                    # If not found in the same row, check the next row if exists\n",
    "                    if i + 1 < len(rows):\n",
    "                        next_row_cells = rows[i + 1].find_all(['td'])\n",
    "                        for value_cell in next_row_cells[1:]: #start from second cell so no 'Basic'\n",
    "                            value_text = value_cell.get_text(strip = True)\n",
    "                            if re.search(r'[0-9]', value_text): # Make sure there are numbers in the cell\n",
    "                                return parse_number(value_text)\n",
    "                            \n",
    "    return 0  # Return 0 if no valid value is found\n",
    "\n",
    "\n",
    "for i in range(50) :\n",
    " soup = BeautifulSoup(html_contents[i], 'html.parser')\n",
    " print('file',i+1,html_ls[i])\n",
    " expression = find_most_similar_cell(soup)\n",
    " val = find_value_after_label(soup, expression)\n",
    " result.loc[len(result)] = [html_ls[i], val] \n",
    " print(expression,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "082005ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>EPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000004977-20-000054.html</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000008947-20-000044.html</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000046080-20-000050.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000066570-20-000013.html</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000314808-20-000062.html</td>\n",
       "      <td>-15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000706129-20-000012.html</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000846617-20-000024.html</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000874766-20-000033.html</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0000875320-20-000014.html</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000892537-20-000010.html</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000895419-20-000042.html</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000939057-20-000186.html</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000950103-20-008424.html</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001008654-20-000048.html</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0001104659-20-052683.html</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0001104659-20-052792.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0001104659-20-053353.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0001104659-20-053534.html</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0001104659-20-053563.html</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0001140361-20-010070.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0001141391-20-000089.html</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0001157523-20-000597.html</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0001157523-20-000599.html</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0001157523-20-000600.html</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0001165002-20-000083.html</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0001171843-20-003035.html</td>\n",
       "      <td>-6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0001193125-20-124288.html</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0001193125-20-124568.html</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0001193125-20-126089.html</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0001193125-20-126683.html</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0001289945-20-000036.html</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0001299709-20-000078.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0001323885-20-000027.html</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0001373715-20-000098.html</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0001423689-20-000040.html</td>\n",
       "      <td>-4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0001436425-20-000011.html</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0001538263-20-000014.html</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0001564590-20-019396.html</td>\n",
       "      <td>-3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0001564590-20-019421.html</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0001564590-20-019431.html</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0001564590-20-019442.html</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0001564590-20-019726.html</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0001564590-20-019755.html</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0001564590-20-019760.html</td>\n",
       "      <td>-2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0001576427-20-000032.html</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0001620459-20-000067.html</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0001678463-20-000062.html</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0001691303-20-000019.html</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0001720635-20-000018.html</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0001722482-20-000089.html</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename    EPS\n",
       "0   0000004977-20-000054.html   0.78\n",
       "1   0000008947-20-000044.html  -0.41\n",
       "2   0000046080-20-000050.html   0.00\n",
       "3   0000066570-20-000013.html   1.18\n",
       "4   0000314808-20-000062.html -15.19\n",
       "5   0000706129-20-000012.html   0.26\n",
       "6   0000846617-20-000024.html   0.47\n",
       "7   0000874766-20-000033.html   0.74\n",
       "8   0000875320-20-000014.html   2.32\n",
       "9   0000892537-20-000010.html   0.71\n",
       "10  0000895419-20-000042.html  -0.57\n",
       "11  0000939057-20-000186.html   0.61\n",
       "12  0000950103-20-008424.html   0.24\n",
       "13  0001008654-20-000048.html  -0.16\n",
       "14  0001104659-20-052683.html  -0.42\n",
       "15  0001104659-20-052792.html   0.00\n",
       "16  0001104659-20-053353.html   0.00\n",
       "17  0001104659-20-053534.html   0.67\n",
       "18  0001104659-20-053563.html   3.17\n",
       "19  0001140361-20-010070.html   0.00\n",
       "20  0001141391-20-000089.html   1.68\n",
       "21  0001157523-20-000597.html  -0.03\n",
       "22  0001157523-20-000599.html   0.57\n",
       "23  0001157523-20-000600.html   0.11\n",
       "24  0001165002-20-000083.html   0.13\n",
       "25  0001171843-20-003035.html  -6.79\n",
       "26  0001193125-20-124288.html   2.01\n",
       "27  0001193125-20-124568.html   0.30\n",
       "28  0001193125-20-126089.html   1.41\n",
       "29  0001193125-20-126683.html   1.52\n",
       "30  0001289945-20-000036.html  -0.24\n",
       "31  0001299709-20-000078.html   0.00\n",
       "32  0001323885-20-000027.html  -0.42\n",
       "33  0001373715-20-000098.html   0.25\n",
       "34  0001423689-20-000040.html  -4.46\n",
       "35  0001436425-20-000011.html   0.21\n",
       "36  0001538263-20-000014.html   0.00\n",
       "37  0001564590-20-019396.html  -3.15\n",
       "38  0001564590-20-019421.html  -0.24\n",
       "39  0001564590-20-019431.html   1.08\n",
       "40  0001564590-20-019442.html   1.00\n",
       "41  0001564590-20-019726.html   0.08\n",
       "42  0001564590-20-019755.html   2.00\n",
       "43  0001564590-20-019760.html  -2.21\n",
       "44  0001576427-20-000032.html   0.62\n",
       "45  0001620459-20-000067.html  -1.21\n",
       "46  0001678463-20-000062.html  -0.22\n",
       "47  0001691303-20-000019.html   0.39\n",
       "48  0001720635-20-000018.html   0.11\n",
       "49  0001722482-20-000089.html   0.05"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#control for outliers\n",
    "result.loc[abs(result['EPS']) > 100, 'EPS'] = 0\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ef7c6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('output.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbb614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119df12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
